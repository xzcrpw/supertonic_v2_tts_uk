# ğŸ‡ºğŸ‡¦ Supertonic v2 TTS - Ukrainian

ĞŸĞ¾Ğ²Ğ½Ğ° Ñ€ĞµÑ–Ğ¼Ğ¿Ğ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ñ–Ñ **Supertonic v2 TTS** Ğ´Ğ»Ñ Ñ‚Ñ€ĞµĞ½ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ· ÑƒĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ¾Ñ— Ğ¼Ğ¾Ğ²Ğ¸.

> **Paper**: [Supertonic: Lightweight Text-to-Speech for Super-Diverse Settings](https://arxiv.org/abs/2509.11084)

## ğŸ¯ Features

- **66M Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ–Ğ²** (ĞºĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½Ğ° Ğ°Ñ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°)
- **44.1kHz** Ğ²Ğ¸ÑĞ¾ĞºĞ¾ÑĞºÑ–ÑĞ½Ğ¸Ğ¹ Ğ°ÑƒĞ´Ñ–Ğ¾ Ğ²Ğ¸Ñ…Ñ–Ğ´
- **Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ° Ğ¼Ğ¾Ğ²Ğ°** Ğ· Ğ½ÑƒĞ»Ñ
- **Character-level** Ñ‚Ğ¾ĞºĞµĞ½Ñ–Ğ·Ğ°Ñ†Ñ–Ñ (Ğ±ĞµĞ· G2P)
- **Flow-matching** Ğ´Ğ»Ñ ÑĞºÑ–ÑĞ½Ğ¾Ñ— Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ñ–Ñ—
- **ONNX export** Ğ´Ğ»Ñ production

## ğŸ“Š ĞÑ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°

| Module | Parameters | Description |
|--------|-----------|-------------|
| Speech Autoencoder | ~47M | Vocos-based encoder/decoder Ğ· ISTFT |
| Text-to-Latent | ~19M | Flow-matching Ğ· LARoPE (Î³=10) |
| Duration Predictor | ~0.5M | Ğ¨Ğ²Ğ¸Ğ´ĞºĞµ L1 Ñ‚Ñ€ĞµĞ½ÑƒĞ²Ğ°Ğ½Ğ½Ñ |

## ğŸš€ Quick Start

### Vast.ai Setup

```bash
# 1. ĞšĞ»Ğ¾Ğ½ÑƒĞ¹Ñ‚Ğµ Ñ€ĞµĞ¿Ğ¾
git clone https://github.com/your-username/supertonic_v2_tts_uk.git
cd supertonic_v2_tts_uk

# 2. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ñ–Ñ‚ÑŒ setup ÑĞºÑ€Ğ¸Ğ¿Ñ‚
chmod +x scripts/setup_vast.sh
./scripts/setup_vast.sh --minimal
```

### Ğ¢Ñ€ĞµĞ½ÑƒĞ²Ğ°Ğ½Ğ½Ñ

```bash
# 1. Autoencoder (ÑĞ¿Ğ¾Ñ‡Ğ°Ñ‚ĞºÑƒ) - ~7-8 Ğ´Ğ½Ñ–Ğ² Ğ½Ğ° 1Ã—5090
python train_autoencoder.py --config config/default.yaml

# 2. Text-to-Latent - ~4-5 Ğ´Ğ½Ñ–Ğ² Ğ½Ğ° 1Ã—5090
python train_text_to_latent.py --config config/default.yaml \
    --autoencoder-checkpoint checkpoints/autoencoder/checkpoint_final.pt

# 3. Duration Predictor - ~20 Ñ…Ğ²Ğ¸Ğ»Ğ¸Ğ½
python train_duration_predictor.py --config config/default.yaml
```

### Inference

```bash
python inference.py \
    --text "ĞŸÑ€Ğ¸Ğ²Ñ–Ñ‚, ÑĞº ÑĞ¿Ñ€Ğ°Ğ²Ğ¸?" \
    --reference samples/reference.wav \
    --output output.wav
```

## ğŸ“š Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¸

### Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ° Ğ¼Ğ¾Ğ²Ğ°

| Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ | Ğ“Ğ¾Ğ´Ğ¸Ğ½ | Ğ¡Ğ¿Ñ–ĞºĞµÑ€Ñ–Ğ² | ĞŸĞ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½Ñ |
|---------|-------|----------|-----------|
| **OpenTTS LADA** | ~5 | 1 (female) | [HuggingFace](https://huggingface.co/datasets/speech-uk/opentts-lada) âœ… |
| **OpenTTS TETIANA** | ~5 | 1 (female) | [HuggingFace](https://huggingface.co/datasets/speech-uk/opentts-tetiana) âœ… |
| **OpenTTS KATERYNA** | ~5 | 1 (female) | [HuggingFace](https://huggingface.co/datasets/speech-uk/opentts-kateryna) âœ… |
| **OpenTTS MYKYTA** | ~5 | 1 (male) | [HuggingFace](https://huggingface.co/datasets/speech-uk/opentts-mykyta) âœ… |
| **OpenTTS OLEKSA** | ~5 | 1 (male) | [HuggingFace](https://huggingface.co/datasets/speech-uk/opentts-oleksa) âœ… |
| **Ukrainian Podcasts** | ~100+ | Many | [HuggingFace](https://huggingface.co/datasets/taras-sereda/uk-pods) âœ… |
| **Common Voice UK** | ~80 | 1000+ | [Mozilla](https://commonvoice.mozilla.org/uk/datasets) |
| **Voice of America** | ~390 | Many | [HuggingFace](https://huggingface.co/datasets/speech-uk/voice-of-america) âœ… |
| **Broadcast Speech** | ~300 | Many | [HuggingFace](https://huggingface.co/datasets/Yehor/broadcast-speech-uk) âœ… |
| **Compiled Dataset** | ~1200 | Many | [NextCloud](https://nx16725.your-storageshare.de/s/cAbcBeXtdz7znDN) / [Torrent](https://academictorrents.com/details/fcf8bb60c59e9eb583df003d54ed61776650beb8) |

> âš ï¸ **M-AILABS** (caito.de) Ğ½Ğ°Ñ€Ğ°Ğ·Ñ– **Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¸Ğ¹**. Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ¹Ñ‚Ğµ OpenTTS voices Ğ·Ğ°Ğ¼Ñ–ÑÑ‚ÑŒ Ğ½ÑŒĞ¾Ğ³Ğ¾.

### ĞĞ½Ğ³Ğ»Ñ–Ğ¹ÑÑŒĞºĞ° (Ğ´Ğ»Ñ pretrain)

| Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ | Ğ“Ğ¾Ğ´Ğ¸Ğ½ | ĞŸĞ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½Ñ |
|---------|-------|-----------|
| LJSpeech | 24 | [Link](https://keithito.com/LJ-Speech-Dataset/) |
| LibriTTS-R | 585 | [Link](https://www.openslr.org/141/) |

### Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ

```bash
# ĞœÑ–Ğ½Ñ–Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ğ½Ğ°Ğ±Ñ–Ñ€ (~50GB)
python scripts/download_datasets.py --minimal

# ĞŸĞ¾Ğ²Ğ½Ğ¸Ğ¹ Ğ½Ğ°Ğ±Ñ–Ñ€ (~500GB)
python scripts/download_datasets.py --full
```

## ğŸ–¥ï¸ Vast.ai Configuration

### ğŸ† Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ¾Ğ²Ğ°Ğ½Ñ– GPU (Ñ†Ñ–Ğ½Ğ°/ÑˆĞ²Ğ¸Ğ´ĞºÑ–ÑÑ‚ÑŒ)

| GPU | Ğ¦Ñ–Ğ½Ğ°/Ğ³Ğ¾Ğ´ | Ğ§Ğ°Ñ | Ğ’Ğ°Ñ€Ñ‚Ñ–ÑÑ‚ÑŒ | Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ñ |
|-----|----------|-----|----------|--------------|
| **A100 40GB (Italy)** | $0.152 | ~7 Ğ´Ğ½Ñ–Ğ² | **~$26** | ğŸ’° ĞĞ°Ğ¹Ğ´ĞµÑˆĞµĞ²ÑˆĞµ |
| 2Ã— A100 40GB (Italy) | $0.299 | ~4 Ğ´Ğ½Ñ– | ~$29 | Ğ¨Ğ²Ğ¸Ğ´ĞºĞ¾ + Ğ´ĞµÑˆĞµĞ²Ğ¾ |
| **H100 SXM (India)** | $0.746 | ~2-3 Ğ´Ğ½Ñ– | **~$35-45** | ğŸš€ ĞĞ°Ğ¹ÑˆĞ²Ğ¸Ğ´ÑˆĞµ |
| RTX 4090 (Portugal) | $0.155 | ~14 Ğ´Ğ½Ñ–Ğ² | ~$52 | Backup |
| RTX PRO 6000 Blackwell | $0.413 | ~5-6 Ğ´Ğ½Ñ–Ğ² | ~$55 | 96GB VRAM |

### ğŸš€ H100 SXM - ĞĞ°Ğ¹ÑˆĞ²Ğ¸Ğ´ÑˆĞ¸Ğ¹ Ğ²Ğ°Ñ€Ñ–Ğ°Ğ½Ñ‚

```bash
# ĞšĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ñ Ğ´Ğ»Ñ H100 80GB
./scripts/train_h100.sh
# Ğ°Ğ±Ğ¾
python train_autoencoder.py --config config/h100_optimized.yaml
```

**ĞŸĞµÑ€ĞµĞ²Ğ°Ğ³Ğ¸ H100:**
- Transformer Engine (FP8) â€” 2Ã— speedup
- 3,350 GB/s memory bandwidth
- 80GB VRAM â†’ batch_size=48-128

### Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Template

- **PyTorch (Vast)** Ğ· Jupyter
- CUDA 12.x

## ğŸ“ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñƒ

```
supertonic_v2_tts_uk/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ default.yaml           # ĞšĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ñ
â”œâ”€â”€ supertonic/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ attention.py       # Multi-head attention Ğ· RoPE
â”‚   â”‚   â”œâ”€â”€ convnext.py        # ConvNeXt blocks
â”‚   â”‚   â”œâ”€â”€ larope.py          # Length-Aware RoPE
â”‚   â”‚   â”œâ”€â”€ speech_autoencoder.py  # Encoder/Decoder/Discriminators
â”‚   â”‚   â”œâ”€â”€ text_to_latent.py  # Textâ†’Latent flow-matching
â”‚   â”‚   â””â”€â”€ duration_predictor.py
â”‚   â”œâ”€â”€ losses/
â”‚   â”‚   â”œâ”€â”€ autoencoder_loss.py    # GAN + Mel + FM loss
â”‚   â”‚   â”œâ”€â”€ flow_matching_loss.py  # CFM loss + ODE solver
â”‚   â”‚   â””â”€â”€ duration_loss.py
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ preprocessing.py   # Audio processing
â”‚       â”œâ”€â”€ tokenizer.py       # Multilingual tokenizer
â”‚       â”œâ”€â”€ dataset.py         # Dataset classes
â”‚       â””â”€â”€ collate.py         # Batch collation
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_vast.sh          # Vast.ai setup
â”‚   â”œâ”€â”€ download_datasets.py   # Dataset downloader
â”‚   â””â”€â”€ prepare_manifest.py    # Manifest preparation
â”œâ”€â”€ train_autoencoder.py       # Autoencoder training
â”œâ”€â”€ train_text_to_latent.py    # TTS training
â”œâ”€â”€ train_duration_predictor.py
â”œâ”€â”€ inference.py               # Synthesis pipeline
â”œâ”€â”€ export_onnx.py             # ONNX export
â””â”€â”€ requirements.txt
```

## âš™ï¸ ĞšĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ñ

ĞÑĞ½Ğ¾Ğ²Ğ½Ñ– Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸ Ğ² `config/default.yaml`:

```yaml
# Audio
audio:
  sample_rate: 44100
  n_fft: 2048
  hop_length: 512
  n_mels: 228

# Latent space
latent:
  dim: 24
  temporal_compression: 6  # Kc

# Flow matching
flow_matching:
  sigma_min: 1.0e-8
  p_uncond: 0.05           # CFG probability
  cfg_scale: 3.0           # Inference CFG scale
  nfe: 32                  # ODE steps

# LARoPE
larope:
  gamma: 10                # Critical for alignment!
```

## ğŸ“ˆ Ğ¢Ñ€ĞµĞ½ÑƒĞ²Ğ°Ğ½Ğ½Ñ

### Ğ•Ñ‚Ğ°Ğ¿ 1: Autoencoder

```bash
python train_autoencoder.py \
    --config config/default.yaml \
    --data-dir data/raw \
    --batch-size 16 \
    --epochs 50
```

**Loss weights**: Î»_recon=45, Î»_adv=1, Î»_fm=0.1

### Ğ•Ñ‚Ğ°Ğ¿ 2: Text-to-Latent

```bash
python train_text_to_latent.py \
    --config config/default.yaml \
    --autoencoder-checkpoint checkpoints/autoencoder/checkpoint_final.pt \
    --batch-size 64 \
    --expansion-factor 4 \
    --iterations 700000
```

**Context-Sharing**: B=64, Ke=4 â†’ effective batch = 256

### Ğ•Ñ‚Ğ°Ğ¿ 3: Duration Predictor

```bash
python train_duration_predictor.py \
    --config config/default.yaml \
    --iterations 3000
```

## ğŸ”§ ONNX Export

```bash
python export_onnx.py \
    --checkpoint-dir checkpoints \
    --output-dir onnx_models \
    --opset 17
```

Outputs:
- `latent_encoder.onnx`
- `latent_decoder.onnx`
- `text_encoder.onnx`
- `reference_encoder.onnx`
- `vector_field.onnx`
- `duration_predictor.onnx`

Total: ~260MB

## ğŸ“Š Benchmarks

Target metrics (based on paper):

| Metric | Target |
|--------|--------|
| Word Error Rate (WER) | <3% |
| Speaker Similarity | >0.85 |
| MOS | >4.0 |
| RTF (1Ã—5090) | <0.1 |

## ğŸ”— Resources

- [Supertonic v2 Paper](https://arxiv.org/abs/2509.11084)
- [Ukrainian TTS Resources](https://github.com/egorsmkv/speech-recognition-uk)
- [HuggingFace speech-uk](https://huggingface.co/speech-uk)
- [Discord: Ukrainian Data Science](https://bit.ly/discord-uds)

## ğŸ“ Citation

```bibtex
@article{supertonic2025,
  title={Supertonic: Lightweight Text-to-Speech for Super-Diverse Settings},
  author={...},
  journal={arXiv preprint arXiv:2509.11084},
  year={2025}
}
```

## ğŸ“œ License

MIT License

## ğŸ™ Acknowledgements

- [egorsmkv/speech-recognition-uk](https://github.com/egorsmkv/speech-recognition-uk) - Ukrainian speech resources
- [Yehor/opentts-uk](https://huggingface.co/datasets/Yehor/opentts-uk) - OpenTTS voices
- [Mozilla Common Voice](https://commonvoice.mozilla.org/) - Ukrainian dataset
- [speech-uk](https://huggingface.co/speech-uk) - HuggingFace organization
