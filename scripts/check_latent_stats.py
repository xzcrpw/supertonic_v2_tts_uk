# scripts/check_latent_stats.py
import torch
import sys
from pathlib import Path
sys.path.insert(0, ".")
from supertonic.models.speech_autoencoder import LatentEncoder
from supertonic.data.preprocessing import AudioProcessor

def check_stats():
    device = "cuda"
    # Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ ÑĞ²Ñ–Ğ¹ Ñ‡ĞµĞºĞ¿Ğ¾Ñ–Ğ½Ñ‚ Ğ°Ğ²Ñ‚Ğ¾ĞµĞ½ĞºĞ¾Ğ´ĞµÑ€Ğ°
    ckpt_path = "checkpoints/autoencoder/checkpoint_150000.pt"
    
    print(f"Loading {ckpt_path}...")
    ckpt = torch.load(ckpt_path, map_location=device)
    
    # Init encoder
    encoder = LatentEncoder(input_dim=100, hidden_dim=512, output_dim=24, num_blocks=10).to(device)
    encoder.load_state_dict(ckpt["encoder"])
    encoder.eval()
    
    # Init processor
    processor = AudioProcessor(sample_rate=22050, n_mels=100)
    
    # Load sample audio (any wav file from your data)
    # Ğ—Ğ¼Ñ–Ğ½Ğ¸ ÑˆĞ»ÑÑ… Ğ½Ğ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ñ„Ğ°Ğ¹Ğ»!
    audio_path = "data/audio/opentts/lada/lada_000001.wav" 
    audio = processor.load(audio_path).to(device)
    mel = processor.compute_mel(audio).unsqueeze(0)
    
    with torch.no_grad():
        latent = encoder(mel)
    
    print("\nğŸ“Š LATENT STATISTICS:")
    print(f"Mean: {latent.mean().item():.4f}")
    print(f"Std:  {latent.std().item():.4f}")
    print(f"Min:  {latent.min().item():.4f}")
    print(f"Max:  {latent.max().item():.4f}")
    
    if abs(latent.mean().item()) > 1.0 or latent.std().item() > 2.0:
        print("\nâŒ CRITICAL: Latents are NOT normalized!")
        print("Flow Matching requires std â‰ˆ 1.0. You must normalize latents during Stage 2 training.")
    else:
        print("\nâœ… Latents look okay-ish (but check if they are centered).")

if __name__ == "__main__":
    check_stats()