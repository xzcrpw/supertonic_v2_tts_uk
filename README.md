# ğŸ‡ºğŸ‡¦ Supertonic v2 TTS - Ukrainian

ĞŸĞ¾Ğ²Ğ½Ğ° Ñ€ĞµÑ–Ğ¼Ğ¿Ğ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ñ–Ñ **Supertonic v2 TTS** Ğ´Ğ»Ñ Ñ‚Ñ€ĞµĞ½ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ· ÑƒĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ¾Ñ— Ğ¼Ğ¾Ğ²Ğ¸.

> **Paper**: [Supertonic: Lightweight Text-to-Speech for Super-Diverse Settings](https://arxiv.org/abs/2509.11084)

## ğŸ¯ Features

- **66M Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ–Ğ²** (ĞºĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½Ğ° Ğ°Ñ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°)
- **44.1kHz** Ğ²Ğ¸ÑĞ¾ĞºĞ¾ÑĞºÑ–ÑĞ½Ğ¸Ğ¹ Ğ°ÑƒĞ´Ñ–Ğ¾ Ğ²Ğ¸Ñ…Ñ–Ğ´
- **Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ° Ğ¼Ğ¾Ğ²Ğ°** Ğ· Ğ½ÑƒĞ»Ñ
- **Character-level** Ñ‚Ğ¾ĞºĞµĞ½Ñ–Ğ·Ğ°Ñ†Ñ–Ñ (Ğ±ĞµĞ· G2P)
- **Flow-matching** Ğ´Ğ»Ñ ÑĞºÑ–ÑĞ½Ğ¾Ñ— Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ñ–Ñ—
- **ONNX export** Ğ´Ğ»Ñ production

## ğŸ“Š ĞÑ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°

| Module | Parameters | Description |
|--------|-----------|-------------|
| Speech Autoencoder | ~47M | Vocos-based encoder/decoder Ğ· ISTFT |
| Text-to-Latent | ~19M | Flow-matching Ğ· LARoPE (Î³=10) |
| Duration Predictor | ~0.5M | Ğ¨Ğ²Ğ¸Ğ´ĞºĞµ L1 Ñ‚Ñ€ĞµĞ½ÑƒĞ²Ğ°Ğ½Ğ½Ñ |

## ğŸš€ Quick Start

### Vast.ai Setup

```bash
# 1. ĞšĞ»Ğ¾Ğ½ÑƒĞ¹Ñ‚Ğµ Ñ€ĞµĞ¿Ğ¾
git clone https://github.com/your-username/supertonic_v2_tts_uk.git
cd supertonic_v2_tts_uk

# 2. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ñ–Ñ‚ÑŒ setup ÑĞºÑ€Ğ¸Ğ¿Ñ‚
chmod +x scripts/setup_vast.sh
./scripts/setup_vast.sh --minimal
```

### Ğ¢Ñ€ĞµĞ½ÑƒĞ²Ğ°Ğ½Ğ½Ñ

```bash
# 1. Autoencoder (ÑĞ¿Ğ¾Ñ‡Ğ°Ñ‚ĞºÑƒ) - ~7-8 Ğ´Ğ½Ñ–Ğ² Ğ½Ğ° 1Ã—5090
python train_autoencoder.py --config config/default.yaml

# 2. Text-to-Latent - ~4-5 Ğ´Ğ½Ñ–Ğ² Ğ½Ğ° 1Ã—5090
python train_text_to_latent.py --config config/default.yaml \
    --autoencoder-checkpoint checkpoints/autoencoder/checkpoint_final.pt

# 3. Duration Predictor - ~20 Ñ…Ğ²Ğ¸Ğ»Ğ¸Ğ½
python train_duration_predictor.py --config config/default.yaml
```

### Inference

```bash
python inference.py \
    --text "ĞŸÑ€Ğ¸Ğ²Ñ–Ñ‚, ÑĞº ÑĞ¿Ñ€Ğ°Ğ²Ğ¸?" \
    --reference samples/reference.wav \
    --output output.wav
```

## ğŸ“š Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¸

### Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ° Ğ¼Ğ¾Ğ²Ğ°

| Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ | Ğ“Ğ¾Ğ´Ğ¸Ğ½ | Ğ¡Ğ¿Ñ–ĞºĞµÑ€Ñ–Ğ² | ĞŸĞ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½Ñ |
|---------|-------|----------|-----------|
| **M-AILABS Ukrainian** | ~20 | 2 | [Download](http://www.caito.de/data/Training/stt_tts/uk_UK.tgz) |
| **OpenTTS-UK** | ~10 | 5 | [HuggingFace](https://huggingface.co/datasets/Yehor/opentts-uk) |
| **Common Voice UK** | ~80 | 1000+ | [Mozilla](https://commonvoice.mozilla.org/uk/datasets) |
| **Voice of America** | ~390 | Many | [HuggingFace](https://huggingface.co/datasets/speech-uk/voice-of-america) |
| **Broadcast Speech** | ~300 | Many | [HuggingFace](https://huggingface.co/datasets/Yehor/broadcast-speech-uk) |

### ĞĞ½Ğ³Ğ»Ñ–Ğ¹ÑÑŒĞºĞ° (Ğ´Ğ»Ñ pretrain)

| Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚ | Ğ“Ğ¾Ğ´Ğ¸Ğ½ | ĞŸĞ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½Ñ |
|---------|-------|-----------|
| LJSpeech | 24 | [Link](https://keithito.com/LJ-Speech-Dataset/) |
| LibriTTS-R | 585 | [Link](https://www.openslr.org/141/) |

### Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ

```bash
# ĞœÑ–Ğ½Ñ–Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ğ½Ğ°Ğ±Ñ–Ñ€ (~50GB)
python scripts/download_datasets.py --minimal

# ĞŸĞ¾Ğ²Ğ½Ğ¸Ğ¹ Ğ½Ğ°Ğ±Ñ–Ñ€ (~500GB)
python scripts/download_datasets.py --full
```

## ğŸ–¥ï¸ Vast.ai Configuration

### Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Template

- **PyTorch (Vast)** Ğ· Jupyter
- CUDA 12.x

### Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Instance

| GPU | Ğ¦Ñ–Ğ½Ğ°/Ğ³Ğ¾Ğ´ | Storage | Ğ§Ğ°Ñ Ñ‚Ñ€ĞµĞ½ÑƒĞ²Ğ°Ğ½Ğ½Ñ |
|-----|---------|---------|----------------|
| 1Ã— RTX 5090 | $0.19-0.22 | 200 GB | ~12-14 Ğ´Ğ½Ñ–Ğ² |
| 2Ã— RTX 5090 | $0.35-0.45 | 200 GB | ~6-7 Ğ´Ğ½Ñ–Ğ² |

**Ğ—Ğ°Ğ³Ğ°Ğ»ÑŒĞ½Ğ° Ğ²Ğ°Ñ€Ñ‚Ñ–ÑÑ‚ÑŒ**: ~$55-70

### ĞĞ°Ğ¹ĞºÑ€Ğ°Ñ‰Ñ– Ğ²Ğ°Ñ€Ñ–Ğ°Ğ½Ñ‚Ğ¸ (ÑÑ‚Ğ°Ğ½Ğ¾Ğ¼ Ğ½Ğ° 2026):

- `host:96199` (Washington) - **$0.188/hr** - Ğ½Ğ°Ğ¹Ğ´ĞµÑˆĞµĞ²ÑˆĞ¸Ğ¹
- `host:155385` (CN) - $0.213/hr - verified 5 months

## ğŸ“ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñƒ

```
supertonic_v2_tts_uk/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ default.yaml           # ĞšĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ñ
â”œâ”€â”€ supertonic/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ attention.py       # Multi-head attention Ğ· RoPE
â”‚   â”‚   â”œâ”€â”€ convnext.py        # ConvNeXt blocks
â”‚   â”‚   â”œâ”€â”€ larope.py          # Length-Aware RoPE
â”‚   â”‚   â”œâ”€â”€ speech_autoencoder.py  # Encoder/Decoder/Discriminators
â”‚   â”‚   â”œâ”€â”€ text_to_latent.py  # Textâ†’Latent flow-matching
â”‚   â”‚   â””â”€â”€ duration_predictor.py
â”‚   â”œâ”€â”€ losses/
â”‚   â”‚   â”œâ”€â”€ autoencoder_loss.py    # GAN + Mel + FM loss
â”‚   â”‚   â”œâ”€â”€ flow_matching_loss.py  # CFM loss + ODE solver
â”‚   â”‚   â””â”€â”€ duration_loss.py
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ preprocessing.py   # Audio processing
â”‚       â”œâ”€â”€ tokenizer.py       # Multilingual tokenizer
â”‚       â”œâ”€â”€ dataset.py         # Dataset classes
â”‚       â””â”€â”€ collate.py         # Batch collation
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_vast.sh          # Vast.ai setup
â”‚   â”œâ”€â”€ download_datasets.py   # Dataset downloader
â”‚   â””â”€â”€ prepare_manifest.py    # Manifest preparation
â”œâ”€â”€ train_autoencoder.py       # Autoencoder training
â”œâ”€â”€ train_text_to_latent.py    # TTS training
â”œâ”€â”€ train_duration_predictor.py
â”œâ”€â”€ inference.py               # Synthesis pipeline
â”œâ”€â”€ export_onnx.py             # ONNX export
â””â”€â”€ requirements.txt
```

## âš™ï¸ ĞšĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ñ

ĞÑĞ½Ğ¾Ğ²Ğ½Ñ– Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸ Ğ² `config/default.yaml`:

```yaml
# Audio
audio:
  sample_rate: 44100
  n_fft: 2048
  hop_length: 512
  n_mels: 228

# Latent space
latent:
  dim: 24
  temporal_compression: 6  # Kc

# Flow matching
flow_matching:
  sigma_min: 1.0e-8
  p_uncond: 0.05           # CFG probability
  cfg_scale: 3.0           # Inference CFG scale
  nfe: 32                  # ODE steps

# LARoPE
larope:
  gamma: 10                # Critical for alignment!
```

## ğŸ“ˆ Ğ¢Ñ€ĞµĞ½ÑƒĞ²Ğ°Ğ½Ğ½Ñ

### Ğ•Ñ‚Ğ°Ğ¿ 1: Autoencoder

```bash
python train_autoencoder.py \
    --config config/default.yaml \
    --data-dir data/raw \
    --batch-size 16 \
    --epochs 50
```

**Loss weights**: Î»_recon=45, Î»_adv=1, Î»_fm=0.1

### Ğ•Ñ‚Ğ°Ğ¿ 2: Text-to-Latent

```bash
python train_text_to_latent.py \
    --config config/default.yaml \
    --autoencoder-checkpoint checkpoints/autoencoder/checkpoint_final.pt \
    --batch-size 64 \
    --expansion-factor 4 \
    --iterations 700000
```

**Context-Sharing**: B=64, Ke=4 â†’ effective batch = 256

### Ğ•Ñ‚Ğ°Ğ¿ 3: Duration Predictor

```bash
python train_duration_predictor.py \
    --config config/default.yaml \
    --iterations 3000
```

## ğŸ”§ ONNX Export

```bash
python export_onnx.py \
    --checkpoint-dir checkpoints \
    --output-dir onnx_models \
    --opset 17
```

Outputs:
- `latent_encoder.onnx`
- `latent_decoder.onnx`
- `text_encoder.onnx`
- `reference_encoder.onnx`
- `vector_field.onnx`
- `duration_predictor.onnx`

Total: ~260MB

## ğŸ“Š Benchmarks

Target metrics (based on paper):

| Metric | Target |
|--------|--------|
| Word Error Rate (WER) | <3% |
| Speaker Similarity | >0.85 |
| MOS | >4.0 |
| RTF (1Ã—5090) | <0.1 |

## ğŸ”— Resources

- [Supertonic v2 Paper](https://arxiv.org/abs/2509.11084)
- [Ukrainian TTS Resources](https://github.com/egorsmkv/speech-recognition-uk)
- [HuggingFace speech-uk](https://huggingface.co/speech-uk)
- [Discord: Ukrainian Data Science](https://bit.ly/discord-uds)

## ğŸ“ Citation

```bibtex
@article{supertonic2025,
  title={Supertonic: Lightweight Text-to-Speech for Super-Diverse Settings},
  author={...},
  journal={arXiv preprint arXiv:2509.11084},
  year={2025}
}
```

## ğŸ“œ License

MIT License

## ğŸ™ Acknowledgements

- [egorsmkv/speech-recognition-uk](https://github.com/egorsmkv/speech-recognition-uk) - Ukrainian speech resources
- [Yehor/opentts-uk](https://huggingface.co/datasets/Yehor/opentts-uk) - OpenTTS voices
- [Mozilla Common Voice](https://commonvoice.mozilla.org/) - Ukrainian dataset
- [speech-uk](https://huggingface.co/speech-uk) - HuggingFace organization
