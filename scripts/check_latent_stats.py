import torch
import sys
import os
from pathlib import Path

# Ð”Ð¾Ð´Ð°Ñ”Ð¼Ð¾ ÐºÐ¾Ñ€Ñ–Ð½ÑŒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñƒ Ð² ÑˆÐ»ÑÑ…
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from supertonic.models.speech_autoencoder import LatentEncoder
from supertonic.data.preprocessing import AudioProcessor

def strip_ddp_prefix(state_dict):
    """Ð’Ð¸Ð´Ð°Ð»ÑÑ” Ð¿Ñ€ÐµÑ„Ñ–ÐºÑ 'module.' Ð· ÐºÐ»ÑŽÑ‡Ñ–Ð² Ñ‡ÐµÐºÐ¿Ð¾Ñ–Ð½Ñ‚Ð°."""
    new_state_dict = {}
    for k, v in state_dict.items():
        if k.startswith("module."):
            new_state_dict[k[7:]] = v
        else:
            new_state_dict[k] = v
    return new_state_dict

def check_stats():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # Ð¨Ð»ÑÑ… Ð´Ð¾ Ñ‡ÐµÐºÐ¿Ð¾Ñ–Ð½Ñ‚Ð°
    ckpt_path = "checkpoints/autoencoder/checkpoint_150000.pt"
    
    # Ð¨Ð»ÑÑ… Ð´Ð¾ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ñ–Ð¾ (Ð²ÐºÐ°Ð¶Ñ–Ñ‚ÑŒ Ñ–ÑÐ½ÑƒÑŽÑ‡Ð¸Ð¹ Ñ„Ð°Ð¹Ð»!)
    # Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÑ”Ð¼Ð¾ Ð·Ð½Ð°Ð¹Ñ‚Ð¸ Ð±ÑƒÐ´ÑŒ-ÑÐºÐ¸Ð¹ wav Ñ„Ð°Ð¹Ð» Ñƒ data/
    audio_files = list(Path("data").rglob("*.wav"))
    if not audio_files:
        print("âŒ ÐÐµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð¶Ð¾Ð´Ð½Ð¾Ð³Ð¾ .wav Ñ„Ð°Ð¹Ð»Ñƒ Ð² Ð¿Ð°Ð¿Ñ†Ñ– data/")
        return
    audio_path = str(audio_files[0])
    print(f"ðŸŽµ Using audio: {audio_path}")
    
    print(f"ðŸ“¦ Loading {ckpt_path}...")
    try:
        ckpt = torch.load(ckpt_path, map_location=device)
    except FileNotFoundError:
        print(f"âŒ Ð§ÐµÐºÐ¿Ð¾Ñ–Ð½Ñ‚ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾: {ckpt_path}")
        return

    # Ð†Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ ÐµÐ½ÐºÐ¾Ð´ÐµÑ€Ð°
    # ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸ Ð¼Ð°ÑŽÑ‚ÑŒ ÑÐ¿Ñ–Ð²Ð¿Ð°Ð´Ð°Ñ‚Ð¸ Ð· config/22khz_optimal.yaml
    encoder = LatentEncoder(
        input_dim=100,      # n_mels
        hidden_dim=512, 
        output_dim=24, 
        num_blocks=10,
        kernel_size=7
    ).to(device)
    
    # Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð²Ð°Ð³ Ð· Ñ„Ñ–ÐºÑÐ¾Ð¼ DDP
    encoder_state = strip_ddp_prefix(ckpt["encoder"])
    encoder.load_state_dict(encoder_state)
    encoder.eval()
    
    # ÐžÐ±Ñ€Ð¾Ð±ÐºÐ° Ð°ÑƒÐ´Ñ–Ð¾
    processor = AudioProcessor(
        sample_rate=22050, 
        n_mels=100, 
        n_fft=1024, 
        hop_length=256
    )
    
    audio = processor.load(audio_path)
    # ÐžÐ±Ñ€Ñ–Ð¶ÐµÐ¼Ð¾, ÑÐºÑ‰Ð¾ Ð´ÑƒÐ¶Ðµ Ð´Ð¾Ð²Ð³Ðµ, Ñ‰Ð¾Ð± Ð½Ðµ Ð·Ð°Ð±Ð¸Ñ‚Ð¸ Ð¿Ð°Ð¼'ÑÑ‚ÑŒ
    if audio.shape[-1] > 22050 * 10:
        audio = audio[..., :22050 * 10]
        
    mel = processor.compute_mel(audio).unsqueeze(0).to(device)
    
    print("ðŸ”„ Encoding...")
    with torch.no_grad():
        latent = encoder(mel)
    
    print("\nðŸ“Š LATENT STATISTICS:")
    mean = latent.mean().item()
    std = latent.std().item()
    min_val = latent.min().item()
    max_val = latent.max().item()
    
    print(f"  Mean: {mean:.4f}")
    print(f"  Std:  {std:.4f}")
    print(f"  Min:  {min_val:.4f}")
    print(f"  Max:  {max_val:.4f}")
    
    print("\nðŸ§ VERDICT:")
    if abs(mean) > 1.0:
        print("âš ï¸  Mean is shifted (should be close to 0).")
    
    if std > 3.0 or std < 0.3:
        print(f"âŒ CRITICAL: Std is {std:.4f}! Flow Matching expects Std â‰ˆ 1.0.")
        print("   Ð’Ð¸ Ð¿Ð¾Ð²Ð¸Ð½Ð½Ñ– Ð´Ð¾Ð´Ð°Ñ‚Ð¸ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ñ–Ð·Ð°Ñ†Ñ–ÑŽ Ð»Ð°Ñ‚ÐµÐ½Ñ‚Ñ–Ð² Ñƒ train_text_to_latent.py!")
        print(f"   Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ: latent = (latent - {mean:.4f}) / {std:.4f}")
    else:
        print("âœ… Latent stats look acceptable for training.")

if __name__ == "__main__":
    check_stats()